# -*- coding: utf-8 -*-
"""gold investment attractiveness

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S54ej-W_9hVfaDr0BEkqBLToPib5qhCR
"""

# GOLD LONG-TERM VALUATION ENGINE

import numpy as np
import pandas as pd
import yfinance as yf
from pandas_datareader import data as pdr
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
from statsmodels.tsa.arima.model import ARIMA
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout


# DATA

def load_data():
    gold = yf.download("GC=F", start="2000-01-01")["Close"]
    silver = yf.download("SI=F", start="2000-01-01")["Close"]
    sp500 = yf.download("^GSPC", start="2000-01-01")["Close"]
    dxy = yf.download("DX-Y.NYB", start="2000-01-01")["Close"]

    fred = {
        "fedfunds": pdr.DataReader("FEDFUNDS", "fred", "2000-01-01"),
        "cpi": pdr.DataReader("CPIAUCSL", "fred", "2000-01-01"),
        "real_yield": pdr.DataReader("DFII10", "fred", "2000-01-01"),
        "breakeven": pdr.DataReader("T10YIE", "fred", "2000-01-01"),
        "m2": pdr.DataReader("M2SL", "fred", "2000-01-01"),
    }

    df = pd.concat([gold, silver, sp500, dxy] + list(fred.values()), axis=1)
    df.columns = ["gold","silver","sp500","dxy","fedfunds","cpi","real_yield","breakeven","m2"]
    df = df.resample("ME").last().dropna()
    return df



# TARGET: 6-Month Forward Return

def build_target(df):
    df["fwd_6m_return"] = df["gold"].shift(-6) / df["gold"] - 1
    return df.dropna()

# FEATURES

FEATURES = ["silver","sp500","dxy","fedfunds","cpi","real_yield","breakeven","m2"]

# SEQUENCE BUILDER (LSTM)
def make_sequences(X, y, seq=12):
    Xs, ys = [], []
    for i in range(len(X)-seq):
        Xs.append(X[i:i+seq])
        ys.append(y[i+seq])
    return np.array(Xs), np.array(ys)


# LOAD FULL DATA
df_full = load_data()

# SEPARATE "LIVE" DATA (The most recent 12 months)
# We need 12 months to feed the LSTM for today's prediction.
# We CANNOT train on this data because the 6-month future return hasn't happened yet.
df_live = df_full.iloc[-12:].copy()

# BUILD TARGET & TRAIN (On Historical Data)
# This function shifts data by -6 and drops NaNs, removing the recent "live" rows
df_train = build_target(df_full)
X_train = df_train[FEATURES].values
y_train = df_train["fwd_6m_return"].values

# SCALE (Fit on TRAIN, Transform both)
scaler = StandardScaler()
Xs_train = scaler.fit_transform(X_train)        # Learned from history
Xs_live = scaler.transform(df_live[FEATURES].values) # Applied to today

# ARIMA
arima = ARIMA(y_train, order=(2,1,2)).fit()

# ML (Random Forest & XGBoost)
rf = RandomForestRegressor(n_estimators=300)
xgbm = xgb.XGBRegressor(n_estimators=300, max_depth=5)
rf.fit(Xs_train, y_train)
xgbm.fit(Xs_train, y_train)

# LSTM
X_lstm, y_lstm = make_sequences(Xs_train, y_train)
model = Sequential([
    LSTM(64, input_shape=(12, Xs_train.shape[1])),
    Dropout(0.2),
    Dense(1)
])
model.compile("adam","mse")
model.fit(X_lstm, y_lstm, epochs=40, batch_size=16, verbose=0)

# OPTIMAL ENSEMBLE

# 1. LSTM tahminlerini tüm EĞİTİM geçmişi için üret
lstm_preds = model.predict(X_lstm, verbose=0).flatten()

# 2. Diğer modelleri LSTM uzunluğuna eşitle (ilk 12 veriyi kesiyoruz)
# DİKKAT: Burada artık eski 'Xs' değil, 'Xs_train' kullanıyoruz.
arima_preds = arima.predict(start=1, end=len(y_train))[12:]
rf_preds = rf.predict(Xs_train)[12:]
xgbm_preds = xgbm.predict(Xs_train)[12:]

# 3. Hedef değişkeni (y) de eşitle
y_aligned = y_train[12:]

pred_matrix = np.column_stack([
    arima_preds,
    rf_preds,
    xgbm_preds,
    lstm_preds
])

# 4. Ağırlıkları hesapla
weights = np.linalg.lstsq(pred_matrix, y_aligned, rcond=None)[0]
print("Model Ağırlıkları (Weights):", weights)


# VALUATION FUNCTION (Değerleme Fonksiyonu)

def gold_valuation(latest_sequence_scaled, latest_single_scaled):
    # 1. ARIMA Tahmini (İstatistiksel)
    p_arima = arima.forecast()[0]

    # ML (RF & XGBoost tek satırlık veri bekler)
    feat_2d = latest_single_scaled.reshape(1, -1)
    p_rf = rf.predict(feat_2d)[0]
    p_xgbm = xgbm.predict(feat_2d)[0]

    # LSTM(3 Boyutlu veri bekler: 1 örnek, 12 zaman adımı, 8 özellik)
    feat_3d = latest_sequence_scaled.reshape(1, 12, 8)
    p_lstm = model.predict(feat_3d, verbose=0)[0][0]

    # 4. Ağırlıklı Ortalama
    p = np.array([p_arima, p_rf, p_xgbm, p_lstm])
    exp_return = np.dot(p, weights)

    return round(exp_return * 100, 2)

# FINAL PREDICTION

print("6 Month EXPECTED GOLD RETURN (%):", gold_valuation(Xs_live, Xs_live[-1]))